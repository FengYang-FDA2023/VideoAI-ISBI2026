---
layout: default
title: Call for Paper
---

<div class="post" style="text-align: justify;">

<section class="call-intro">
  <h4 class="pageTitle" style="color: #2c3e50;">Call for Paper</h4>
  <h5 class="pageTitle" style="color: #2c3e50;">Introduction  </h5>
  <p>
  Artificial Intelligence and Machine Learning (AI/ML)-enabled medical devices are advancing rapidly to address the evolving needs of patients, clinicians, and manufacturers in the MedTech industry.  However, the pace of technological innovation has outstripped the development of evaluation methods in some instances, creating uncertainty for developers and posing challenges for regulatory bodies charged with ensuring safety, efficacy, and transparency.
</p>
  <p>
  The workshop aims to introduce regulatory science on AI-enabled devices to the ISBI community, with a particular focus on the assessment of medical video AI and uncertainty quantification. These areas present unique challenges, including frame-to-frame variability, motion artifacts, and temporal consistency. We aim to foster dialogue among researchers, clinicians, and regulators to discuss technical and regulatory challenges and help to reduce the gap between development of novel AI technologies and their clinical adoption. We will discuss the development of regulatory science tools, testing methods, and metrics for assessing AI-assisted devices. 
While this workshop will focus on medical video AI systems, assessment many of the concepts generalize to other device types. 
</p>
<h5 class="pageTitle" style="color: #2c3e50;">Rationale  </h5>
  <p>
  The rapid adoption of AI across a broad range of medical devices highlights the need for robust evaluation frameworks and assessment approaches tailored to AI-based technologies. Critical regulatory science challenges include assessing generalizability, interpretability, and uncertainty quantification. Addressing these challenges is essential to support evidence-based regulatory decision-making and to ensure that AI-enabled medical devices are safe and effective.
</p>
  <p>
  Extending these considerations to the domain of medical video AI introduces additional complexities. Medical video AI systems are relatively new, designed to assist care providers by improving the identification of abnormalities within temporally continuous imaging data, including real-time clinical applications. Taking the colonoscopy computer-aided detection (colon-CADe) devices as an example, six colon-CADe devices are authorized for marketing in the US. Disease detection in video imaging procedures differs from many radiology AI applications, which typically operate on static images and potentially non-real time image interpretation. In contrast, video AI systems must handle challenges such as frame-to-frame variability, motion artifacts, and lesion persistence across time, and often the need for real-time prompting as diagnosis are commonly made during the clinical procedure/video collection such that appropriate intervention can be performed. It remains unclear which specific performance metrics and standalone study protocols are adequate to compare colon-CADe algorithms as AI testing protocols and metrics characterizing video-based performance are still evolving. While many ISBI workshops have explored algorithm developments, novel applications and platforms, a significant gap remains tackling practical assessment pitfalls, real‐world deployment hurdles, and core regulatory-science questions necessary for safe clinical translation. Addressing these gaps is essential to ensure AI‐enabled devices perform reliably in the clinical setting. 

  </p>
  <p>
    If you are working on research related to medical AI, clinical deployment, or evaluation, then: <strong>Medical Video AI Assessment and Uncertainty Quantification</strong> is the right place for your work!
  </p>
</section>


  <!-- Topics of Interest -->
  <section class="topics">
    <h4 style="color: #2c3e50;">Topics that will be covered in the workshop:</h4>
    <ul>
      <li>Study designs for benchmarking disease-detection models in medical video-based applications</li>
      <li>Standardized evaluation frameworks/methods for AI-enabled video devices</li>
      <li>Evaluation metrics at potentially multiple levels (e.g., frame-, lesion-, and patient-level) for performance, video detection latency, temporal consistency, false-positive burden, etc.</li>
      <li>Development and curation of reference datasets for medical video AI evaluation</li>
      <li>Methods to quantify, calibrate, and report predictive uncertainty in AI-enabled medical devices, such as computer aided detection (CADe) devices</li>
      <li>Frameworks for regulatory-grade uncertainty analysis and interpretability</li>
      <li>Benchmarking and validation of AI-enabled devices using uncertainty metrics</li>
      <li>Strategies to integrate uncertainty awareness into real-time clinical AI workflows</li>
      <li>Analysis revealing disconnects between AI development, evaluation metrics, and regulatory requirements</li>
      <li>Comparative regulatory science across countries: lessons for global alignment</li>

    </ul>
  </section>

  <!-- Proceedings -->
  <section class="proceedings">
    <h4 style="color: #2c3e50;">Proceedings</h4>
    <p>
      Accepted papers will be published in the ISBI conference proceedings.
    </p>
  </section>

<!-- Paper Format & Submission -->
<section class="paper-format">
  <h4 style="color: #2c3e50;">Paper Format &amp; Submission</h4>
  <p>
    Submissions must be anonymized, use the official
    <a href="https://biomedicalimaging.org/2026/initial-author-instructions/"
       target="_blank"
       rel="noopener">
      IEEE ISBI format
    </a>,
    and be no more than <strong>4 pages of main content</strong> plus up to <strong>1 page for Ethical Standards, Acknowledgements, and References</strong>. So, the maximum length is <strong>five pages</strong> (including this additional content). Manuscripts exceeding 5 pages will be rejected. The <strong>fifth page requires a $200 fee</strong>, which will be paid for during registration.
  </p>
  <p>
    Submit your manuscript via OpenReview:
    <a href="https://openreview.net/group?id=ISBI.org/2026/Workshop/VideoAIandUncertainty"
       target="_blank"
       rel="noopener">
      OpenReview Submission Site
    </a>.
  </p>
</section>


  <!-- Submission Evaluation Criteria -->
  <section class="submission-guidelines">
    <h4 style="color: #2c3e50;">Submission Evaluation Criteria</h4>
    <ol>
      <li><strong>Relevance:</strong> Alignment with AI evaluation, regulatory science, or deployment challenges in healthcare.</li>
      <li><strong>Clarity & Structure:</strong> Logical organization, clear writing, and accessibility to a multidisciplinary audience.</li>
      <li><strong>Empirical Rigor:</strong> Robust measurement or validation of new or existing concepts (for empirical work).</li>
    </ol>
    <p>
      All submissions undergo a <strong>double-blind review</strong>. Please omit author names, affiliations, and
      self-identifying references. Use the official <strong>Springer LNCS</strong> format (Word & LaTeX templates provided).
    </p>
  </section>

  <!-- Important Dates -->
  <section class="important-dates">
    <h4 style="color: #2c3e50;">Important Dates (Anywhere on Earth)</h4>
    <ul>
    <li><strong>Full paper deadline:</strong> Feb 15th, 2026</li>
    <li><strong>Notification of acceptance:</strong> Feb 28th, 2026</li>
    <li><strong>Camera-ready deadline:</strong> March 7th, 2026 (No deadline extension)</li>
    <li><strong>Workshop date:</strong> TBA</li>
    </ul>
  </section>



  <!-- Contact -->
  <section class="contact">
    <h4 style="color: #2c3e50;">Questions?</h4>
    <p>Reach us at <a href="mailto:videoai.isbi2026@gmail.com">videoai.isbi2026@gmail.com</a></p>
  </section>

  <footer style="text-align: center; margin-top: 2em;">
    <p>— Medical Video AI Assessment and Uncertainty Quantification Workshop Team</p>
  </footer>

</div>
